{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch 常用代码片段"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "笔记出处位于知乎文档: [PyTorch常用代码段](https://zhuanlan.zhihu.com/p/104019160)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基本配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "# 如果引用torchvision失败，可能是pillow的组件版本过高\n",
    "# 可以先卸载本地的pillow，然后pip install pillow==6.2.2\n",
    "import torchvision\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.backends.cudnn.version())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可复现性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在硬件设备（CPU、GPU）不同时，完全的可复现性无法保证，即使随机种子相同。但是，在同一个设备上，应该保证可复现性。具体做法是，在程序开始的时候固定torch的随机种子，同时也把numpy的随机种子固定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 显卡设置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果只需要一张显卡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果需要指定多张显卡，比如0，1号显卡。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也可以在命令行运行代码时设置显卡："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA_VISIBLE_DEVICES=0,1 python train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "清除显存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也可以使用在命令行重置GPU的指令"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nvidia-smi --gpu-reset -i 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 张量处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 张量的数据类型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch有9种CPU张量类型和9种GPU张量类型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./image/torch_tensor.jpg\"  alt=\"Tensor types\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 张量基本信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.randn(3,4,5)\n",
    "print(tensor.type())  # 数据类型\n",
    "print(tensor.size())  # 张量的shape，是个元组\n",
    "print(tensor.dim())   # 维度的数量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 命名张量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "张量命名是一个非常有用的方法，这样可以方便地使用维度的名字来做索引或其他操作，大大提高了可读性与易用性，防止出错"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在PyTorch 1.3之前，需要使用注释\n",
    "# Tensor[N, C, H, W]\n",
    "images = torch.randn(32, 3, 56, 56)\n",
    "print(images.size())\n",
    "images.sum(dim = 1)\n",
    "images.select(dim = 1, index = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 只有1.3之后才支持张量命名\n",
    "NCHW = ['N', 'C', 'H', 'W']\n",
    "images = torch.randn(32, 3, 56, 56, names=NCHW)\n",
    "images.sum('C')\n",
    "images.select('C', index=0)\n",
    "# 也可以这么设置\n",
    "tensor = torch.rand(3,4,1,2,names=('C', 'N', 'H', 'W'))\n",
    "# 使用align_to可以对维度方便地排序\n",
    "tensor = tensor.align_to('N', 'C', 'H', 'W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据类型转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置默认类型，pytorch中的Float Tensor远远快于DoubleTensor\n",
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "\n",
    "# 类型转换\n",
    "tensor = tensor.cuda()\n",
    "tensor = tensor.cpu()\n",
    "tensor = tensor.float()\n",
    "tensor = tensor.long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.Tensor与np.ndarray转换"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除了CharTensor，其他所有CPU上的张量都支持转换为numpy格式，然后再转换回来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndarray = tensor.cpu().numpy()\n",
    "tensor = torch.from_numpy(ndarray).float()\n",
    "tensor = torch.from_numpy(ndarray.copy()).float()\n",
    "type(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch.tensor与PIL.Image转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.clamp(tensor * 255, min = 0, max = 255)\n",
    "type(data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不清楚为什么，总是报错\n",
    "# pytorch中的张量默认采用[N, C, H, W]的顺序，并且数据范围在[0,1]，需要进行转置和规范化\n",
    "# torch.Tensor -> PIL.Image\n",
    "image = PIL.Image.fromarray(data).byte().permute(1,2,0).cpu().numpy()\n",
    "# image = torchvision.transforms.functional.to_pil_image(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = torchvision.transforms.functional.to_pil_image(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'./image/lstm_3.png'\n",
    "img_tensor = torch.from_numpy(np.asarray(PIL.Image.open(path))).permute(2,0,1).float() / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 等同torch直接转换\n",
    "img_tensor = torchvision.transforms.functional.to_tensor(PIL.Image.open(path)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image = torchvision.transforms.functional.to_pil_image(img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "整合为读取图片并显示的方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchvision的to_tensor与to_pil_image与PIL实现方式等价，但代码更简洁\n",
    "def load_image(img_path: str):\n",
    "#     img_tensor = torch.from_numpy(np.asarray(PIL.Image.open(img_path))).permute(2,0,1).float() / 255\n",
    "    img_tensor = torchvision.transforms.functional.to_tensor(PIL.Image.open(path)) \n",
    "    new_image = torchvision.transforms.functional.to_pil_image(img_tensor)\n",
    "    return img_tensor, new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor, new_image = load_image(r'./image/lstm_3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(new_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndarray = tensor.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_img = torchvision.transforms.functional.to_pil_image(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_ndarray = np.asarray(small_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_ndarray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_ndarray.reshape(3, 4, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从只包含一个元素的张量中取值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = torch.rand(1).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 张量形变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在将卷积层输入全连接层的情况下通常需要对张量做形变处理，\n",
    "# 相比torch.view，torch.reshape可以自动处理输入张量不连续的情况。\n",
    "tensor = torch.rand(2,3,4)\n",
    "print(tensor)\n",
    "shape = (6, 4)\n",
    "tensor = torch.reshape(tensor, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 打乱顺序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.rand(3,3,4)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打乱第一个维度\n",
    "tensor = tensor[torch.randperm(tensor.size(0))]\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打乱第一个维度\n",
    "tensor = tensor[torch.randperm(tensor.size(0))]\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 水平翻转"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch不支持tensor[::-1]这样的负步长操作，水平翻转可以通过张量索引实现\n",
    "# 假设张量的维度为[N, D, H, W].\n",
    "tensor = torch.rand(2, 3, 3, 4)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = tensor[:, :, :, torch.arange(tensor.size(3) - 1, -1, -1).long()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 交换tensor的维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin = torch.randn((2, 3, 4))\n",
    "origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transposed = torch.transpose(origin, 1, 2)\n",
    "transposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transposed.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 复制张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.rand(4, 3, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operation                 |  New/Shared memory | Still in computation graph |\n",
    "tensor.clone()            # |        New         |          Yes               |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor.detach()           # |      Shared        |          No                |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Failed for torch 1.2.0\n",
    "# tensor.detach.clone()()   # |        New         |          No                |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 张量拼接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "注意torch.cat和torch.stack的区别在于torch.cat沿着给定的维度拼接，\n",
    "而torch.stack会新增一维。例如当参数是3个10x5的张量，torch.cat的结果是30x5的张量，\n",
    "而torch.stack的结果是3x10x5的张量。\n",
    "'''\n",
    "tensor_list = []\n",
    "for i in range(3):\n",
    "    tensor_list.append(torch.rand(4, 3))\n",
    "\n",
    "tensor_cat = torch.cat(tensor_list, dim=0)\n",
    "tensor_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_stack = torch.stack(tensor_list, dim=0)\n",
    "tensor_stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将整数标签转为one-hot编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor([1, 2, 0, 3])\n",
    "N = tensor.size(0)\n",
    "num_classes = 4\n",
    "one_hot = torch.zeros(N, num_classes).long()\n",
    "one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot.scatter_(dim=1, \n",
    "                 index=torch.unsqueeze(tensor, dim=1), \n",
    "                 src=torch.ones(N, num_classes).long())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 得到非零元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nonzero(tensor) # index of non-zero elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nonzero(tensor==0) # index of zero elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nonzero(tensor).size(0) # number of non-zero elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nonzero(tensor == 0).size(0) # number of zero elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 判断两个张量相等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor1 = torch.rand([3, 4, 5])\n",
    "# tensor1 = torch.tensor([[1, 2, 0, 3], [2, 3, 2, 5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor2 = torch.rand([3, 4, 5])\n",
    "# tensor2 = torch.tensor([1, 2, 0, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.allclose(tensor1, tensor2)  # float tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.equal(tensor1, tensor2)     # int tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 张量扩展"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand tensor of shape 2*3 to shape 2*3*4*4.\n",
    "tensor = torch.rand(2, 3)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.reshape(tensor, (2, 3, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.reshape(tensor, (2, 3, 1, 1)).expand(2, 3, 4, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 矩阵乘法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 二维矩阵乘法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor1_d2 = torch.randn([4, 3])\n",
    "tensor1_d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor2_d2 = torch.randn([3, 5])\n",
    "tensor2_d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mm(tensor1_d2, tensor2_d2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 三维矩阵乘法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor1_d3 = torch.randn([3, 4, 3])\n",
    "tensor1_d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor2_d3 = torch.randn([3, 3, 5])\n",
    "tensor2_d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.bmm(tensor1_d3, tensor2_d3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 点乘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor1_dot = torch.randn([3, 4])\n",
    "tensor1_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor2_dot = torch.randn([3, 4])\n",
    "tensor2_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor1_dot * tensor2_dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算两组数据之间的两两欧氏距离"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用broadcast机制\n",
    "X1 = torch.randn([4, 5])\n",
    "X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1[:, None, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = torch.randn([4, 5])\n",
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1[:, None, :] - X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum((X1[:,None,:] - X2)**2, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sqrt(torch.sum((X1[:,None,:] - X2) ** 2, dim = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型定义和操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一个简单两层卷积网络的示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolutional neural network (2 convolutional layers)\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc = nn.Linear(4*4*32, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet(num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 双线性汇合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100 # N: number of samples\n",
    "D = 3 # D: RGB channels\n",
    "H = 32 # Height\n",
    "W = 32 # Weidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_X = torch.randn(N, D, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_X.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.reshape(origin_X, (N, D, H * W))                        # Assume X has shape N*D*H*W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.transpose(X, 1, 2).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_X = torch.bmm(X, torch.transpose(X, 1, 2)) / (H * W) # Bilinear pooling, 得到100 x 3 x 3的张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_X[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert b_X.size() == (N, D, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_X = torch.reshape(b_X, (N, D, D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_X.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_X[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sqrt(torch.abs(b_X) + 1e-5)[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_X = torch.sign(b_X) * torch.sqrt(torch.abs(b_X) + 1e-5) # Signed-sqrt normalization\n",
    "b_X[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_X = torch.nn.functional.normalize(b_X) # L2 normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_X[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多卡同步 BN（Batch normalization）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当使用 torch.nn.DataParallel 将代码运行在多张 GPU 卡上时，PyTorch 的 BN 层默认操作是各卡上数据独立地计算均值和标准差，同步 BN 使用所有卡上的数据一起计算 BN 层的均值和标准差，缓解了当批量大小（batch size）比较小时对均值和标准差估计不准的情况，是在目标检测等任务中一个有效的提升性能的技巧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sync_bn = torch.nn.SyncBatchNorm(num_features=10, eps=1e-05, momentum=0.1, affine=True, \n",
    "                                 track_running_stats=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将已有网络的所有BN层改为同步BN层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertBNtoSyncBN(module, process_group=None):\n",
    "    '''Recursively replace all BN layers to SyncBN layer.\n",
    "\n",
    "    Args:\n",
    "        module[torch.nn.Module]. Network\n",
    "    '''\n",
    "    if isinstance(module, torch.nn.modules.batchnorm._BatchNorm):\n",
    "        sync_bn = torch.nn.SyncBatchNorm(module.num_features, module.eps, module.momentum, \n",
    "                                         module.affine, module.track_running_stats, process_group)\n",
    "        sync_bn.running_mean = module.running_mean\n",
    "        sync_bn.running_var = module.running_var\n",
    "        if module.affine:\n",
    "            sync_bn.weight = module.weight.clone().detach()\n",
    "            sync_bn.bias = module.bias.clone().detach()\n",
    "        return sync_bn\n",
    "    else:\n",
    "#         for name, child_module in module.named_children():\n",
    "#             setattr(module, name) = convert_syncbn_model(child_module, process_group=process_group)\n",
    "        return module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 类似BN滑动平均"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果要实现类似 BN 滑动平均的操作，在 forward 函数中要使用原地（inplace）操作给滑动平均赋值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "class BN(torch.nn.Module)\n",
    "    def __init__(self):\n",
    "        ...\n",
    "        self.register_buffer('running_mean', torch.zeros(num_features))\n",
    "\n",
    "    def forward(self, X):\n",
    "        ...\n",
    "        self.running_mean += momentum * (current - self.running_mean)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算模型整体参数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet(num_classes=10)\n",
    "num_parameters = sum(torch.numel(parameter) for parameter in model.parameters())\n",
    "num_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看网络中的参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以通过model.state_dict()或者model.named_parameters()函数查看现在的全部可训练参数（包括通过继承得到的父类中的参数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(model.named_parameters())\n",
    "for (name, param) in params:\n",
    "    print(name)\n",
    "    print(param.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型可视化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先需要安装: graphviz，路径为：https://graphviz.gitlab.io/_pages/Download/Download_windows.html\n",
    "\n",
    "安装完毕之后需要设置环境变量路径, 如：C:\\Program Files (x86)\\Graphviz2.38\\bin\n",
    "\n",
    "\n",
    "然后安装python包：\n",
    "- pip install torchviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot, make_dot_from_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_dot(model(torch.randn(18, 1, 16, 16)), params=dict(model.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = nn.Sequential()\n",
    "test_model.add_module('W0', nn.Linear(8, 16))\n",
    "test_model.add_module('tanh', nn.Tanh())\n",
    "test_model.add_module('W1', nn.Linear(16, 1))\n",
    "\n",
    "x = torch.randn(1,8)\n",
    "y = test_model(x)\n",
    "make_dot(y.mean(), params=dict(test_model.named_parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 类似 Keras 的 model.summary() 输出模型信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "安装：\n",
    "- pip install torchsummary or <br>\n",
    "- git clone https://github.com/sksq96/pytorch-summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 简单演示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(test_model.to(device), (1, 16, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model.to(device), (1, 16, 16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 自定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Custom_Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "custom_model = Custom_Net().to(device)\n",
    "\n",
    "summary(custom_model, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VGG 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = models.vgg16().to(device)\n",
    "summary(vgg, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_dot(vgg(torch.randn(1, 3, 224, 224).to(device)), params=dict(vgg.named_parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleConv, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        x1 = self.features(x)\n",
    "        x2 = self.features(y)\n",
    "        return x1, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_model = SimpleConv().to(device)\n",
    "\n",
    "summary(s_model, [(1, 16, 16), (1, 28, 28)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型权重初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_model = ConvNet(num_classes=10).to(device)\n",
    "# 注意 model.modules() 和 model.children() 的区别：\n",
    "# model.modules() 会迭代地遍历模型的所有子层，而 model.children() 只会遍历模型下的一层。\n",
    "# 针对不同的layer类型，使用不同的权重初始化方法\n",
    "for layer in c_model.modules():\n",
    "    # 何凯明提出了针对于relu的初始化方法。pytorch默认使用kaiming正态分布初始化卷积层参数\n",
    "    if isinstance(layer, torch.nn.Conv2d):\n",
    "        torch.nn.init.kaiming_normal_(layer.weight, mode='fan_out',\n",
    "                                      nonlinearity='relu')\n",
    "        if layer.bias is not None:\n",
    "            torch.nn.init.constant_(layer.bias, val=0.0)\n",
    "    elif isinstance(layer, torch.nn.BatchNorm2d):\n",
    "        torch.nn.init.constant_(layer.weight, val=1.0)\n",
    "        torch.nn.init.constant_(layer.bias, val=0.0)\n",
    "    elif isinstance(layer, torch.nn.Linear):\n",
    "        torch.nn.init.xavier_normal_(layer.weight)\n",
    "        if layer.bias is not None:\n",
    "            torch.nn.init.constant_(layer.bias, val=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_value = torch.randn(3, 1, 16, 16)\n",
    "random_value[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用给定的tensor，初始化权重\n",
    "layer.weight = torch.nn.Parameter(random_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer.weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提取模型中的某一层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modules()会返回模型中所有模块的迭代器，它能够访问到最内层。\n",
    "\n",
    "比如self.layer1.conv1这个模块，还有一个与它们相对应的是name_children()属性以及named_modules(),这两个不仅会返回模块的迭代器，还会返回网络层的名字。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet(num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model.to(device), (1, 16, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取模型中的前两层\n",
    "new_model = nn.Sequential(*list(model.children())[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(new_model.to(device), (1, 16, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model = nn.Sequential()\n",
    "# 如果希望提取出模型中的所有卷积层，可以像下面这样操作\n",
    "conv_layer_idx = 0\n",
    "for layer in model.named_modules():\n",
    "    if isinstance(layer[1],nn.Conv2d):\n",
    "        # 原模型的layer名称: layer[0]可能含有.，会引起报错\n",
    "        # 所以需要重置卷积层名称\n",
    "        layer_name = 'conv_{0}'.format(conv_layer_idx)\n",
    "        conv_model.add_module(layer_name, layer[1])\n",
    "        conv_layer_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(conv_model.to(device), (1, 16, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 部分层使用预训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意如果保存的模型是 torch.nn.DataParallel，则当前的模型也需要是"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "model.load_state_dict(torch.load('model.pth'), strict=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将在GPU保存的模型加载到CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "model.load_state_dict(torch.load('model.pth', map_location='cpu'))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入另一个模型的相同部分到新的模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型导入参数时，如果两个模型结构不一致，则直接导入参数会报错。用下面方法可以把另一个模型的相同的部分导入到新的模型中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# model_new代表新的模型\n",
    "# model_saved代表其他模型，比如用torch.load导入的已保存的模型\n",
    "model_new_dict = model_new.state_dict()\n",
    "model_common_dict = {k:v for k, v in model_saved.items() if k in model_new_dict.keys()}\n",
    "model_new_dict.update(model_common_dict)\n",
    "model_new.load_state_dict(model_new_dict)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in model.state_dict().items():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算数据集的均值和标准差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def compute_mean_and_std(dataset):\n",
    "    # 输入PyTorch的dataset，输出均值和标准差\n",
    "    mean_r = 0\n",
    "    mean_g = 0\n",
    "    mean_b = 0\n",
    "\n",
    "    for img, _ in dataset:\n",
    "        img = np.asarray(img) # change PIL Image to numpy array\n",
    "        mean_b += np.mean(img[:, :, 0])\n",
    "        mean_g += np.mean(img[:, :, 1])\n",
    "        mean_r += np.mean(img[:, :, 2])\n",
    "\n",
    "    mean_b /= len(dataset)\n",
    "    mean_g /= len(dataset)\n",
    "    mean_r /= len(dataset)\n",
    "\n",
    "    diff_r = 0\n",
    "    diff_g = 0\n",
    "    diff_b = 0\n",
    "\n",
    "    N = 0\n",
    "\n",
    "    for img, _ in dataset:\n",
    "        img = np.asarray(img)\n",
    "\n",
    "        diff_b += np.sum(np.power(img[:, :, 0] - mean_b, 2))\n",
    "        diff_g += np.sum(np.power(img[:, :, 1] - mean_g, 2))\n",
    "        diff_r += np.sum(np.power(img[:, :, 2] - mean_r, 2))\n",
    "\n",
    "        N += np.prod(img[:, :, 0].shape)\n",
    "\n",
    "    std_b = np.sqrt(diff_b / N)\n",
    "    std_g = np.sqrt(diff_g / N)\n",
    "    std_r = np.sqrt(diff_r / N)\n",
    "\n",
    "    mean = (mean_b.item() / 255.0, mean_g.item() / 255.0, mean_r.item() / 255.0)\n",
    "    std = (std_b.item() / 255.0, std_g.item() / 255.0, std_r.item() / 255.0)\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 得到视频数据基本信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import cv2\n",
    "video = cv2.VideoCapture(mp4_path)\n",
    "height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "num_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "fps = int(video.get(cv2.CAP_PROP_FPS))\n",
    "video.release()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TSN 每段（segment）采样一帧视频"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "K = self._num_segments\n",
    "if is_train:\n",
    "    if num_frames > K:\n",
    "        # Random index for each segment.\n",
    "        frame_indices = torch.randint(\n",
    "            high=num_frames // K, size=(K,), dtype=torch.long)\n",
    "        frame_indices += num_frames // K * torch.arange(K)\n",
    "    else:\n",
    "        frame_indices = torch.randint(\n",
    "            high=num_frames, size=(K - num_frames,), dtype=torch.long)\n",
    "        frame_indices = torch.sort(torch.cat((\n",
    "            torch.arange(num_frames), frame_indices)))[0]\n",
    "else:\n",
    "    if num_frames > K:\n",
    "        # Middle index for each segment.\n",
    "        frame_indices = num_frames / K // 2\n",
    "        frame_indices += num_frames // K * torch.arange(K)\n",
    "    else:\n",
    "        frame_indices = torch.sort(torch.cat((                              \n",
    "            torch.arange(num_frames), torch.arange(K - num_frames))))[0]\n",
    "assert frame_indices.size() == (K,)\n",
    "return [frame_indices[i] for i in range(K)]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 常用训练和验证数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中 ToTensor 操作会将 PIL.Image 或形状为 H×W×D，数值范围为 [0, 255] 的 np.ndarray 转换为形状为 D×H×W，数值范围为 [0.0, 1.0] 的 torch.Tensor。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "train_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomResizedCrop(size=224,\n",
    "                                             scale=(0.08, 1.0)),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                     std=(0.229, 0.224, 0.225)),\n",
    " ])\n",
    "val_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(256),\n",
    "    torchvision.transforms.CenterCrop(224),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                     std=(0.229, 0.224, 0.225)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据加载与处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "%matplotlib inline\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取人脸轮廓的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks_frame = pd.read_csv('./faces/face_landmarks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Face number: {0}'.format(len(landmarks_frame)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取第3行数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2\n",
    "print('Face number: {0}'.format(len(landmarks_frame)))\n",
    "img_name = landmarks_frame.iloc[n, 0]\n",
    "landmarks = landmarks_frame.iloc[n, 1:].values\n",
    "# 将轮廓数据拆为两列，第一列是X轴，第二列是Y轴\n",
    "landmarks = landmarks.astype('float').reshape(-1, 2)\n",
    "\n",
    "print('Image name: {}'.format(img_name))\n",
    "print('Landmarks shape: {}'.format(landmarks.shape))\n",
    "print('First 4 Landmarks: {}'.format(landmarks[:4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "展示数据集第3行人脸轮廓的效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_landmarks(image, landmarks):\n",
    "    \"\"\"Show image with landmarks\"\"\"\n",
    "    plt.imshow(image)\n",
    "    plt.scatter(landmarks[:, 0], landmarks[:, 1], s=10, marker='.', c='r')\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "show_landmarks(io.imread(os.path.join('./faces/', img_name)),\n",
    "               landmarks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset类介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 原理介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.utils.data.Dataset是一个PyTorch用来表示数据集的抽象类。\n",
    "\n",
    "我们用这个类来处理自己的数据集的时候必须继承Dataset,然后重写下面的函数：\n",
    "\n",
    "```__len__```: 使得len(dataset)返回数据集的大小；\n",
    "\n",
    "```__getitem__```：使得支持dataset[i]能够返回第i个数据样本这样的下标操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 创建脸部图像数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 在类的```__init__```函数中完成csv文件的读取工作；\n",
    "- 在类的```__getitem__```函数中完成图片的读取工作。这样是为了减小内存开销，只要在需要用到的时候才将图片读入。\n",
    "- 除此，数据集还会接收一个可以选择的参数transform，用来对图像做一些改变，具体的会在下面进行介绍。\n",
    "- 最终返回的样本数据是一个字典形式的，如下所示：{‘image':image,'landmarks':landmarks}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那么现在我们就可以写出类的定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceLandmarksDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        csv_path = os.path.join(root_dir, csv_file)\n",
    "        self.landmarks_frame = pd.read_csv(csv_path)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.landmarks_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.landmarks_frame.iloc[idx, 0])\n",
    "        image = io.imread(img_name)\n",
    "        landmarks = self.landmarks_frame.iloc[idx, 1:].values\n",
    "        landmarks = landmarks.astype('float').reshape(-1, 2)\n",
    "        sample = {'image': image, 'landmarks': landmarks}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 实例化类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我们对上面定义好的类做实例化，然后在数据样本上进行迭代。我们会打印前4个样本图像及其对应的坐标点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_dataset = FaceLandmarksDataset(csv_file='face_landmarks.csv',\n",
    "                                    root_dir='./faces/')\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "for i in range(len(face_dataset)):\n",
    "    sample = face_dataset[i]\n",
    "    print(i, sample['image'].shape, sample['landmarks'].shape)\n",
    "    ax = plt.subplot(1, 4, i + 1)\n",
    "    plt.tight_layout()\n",
    "    ax.set_title('Sample #{}'.format(i))\n",
    "    ax.axis('off')\n",
    "    show_landmarks(sample['image'], sample['landmarks'])\n",
    "\n",
    "    if i == 3:\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上面显示的图片我们可以看到每张图片的大小都不一样，但往往我们在处理神经网络的输入图像的时候都希望它们有一个相对固定的大小。\n",
    "\n",
    "因此，我们需要一些对图像进行预处理的工作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 实现常用变换功能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们试着写一下这三个常用的变换功能：\n",
    "\n",
    "- Rescale：重新调整图像大小；\n",
    "- RandomCrop：随机从图像中截取一部分；\n",
    "- ToTensor：将numpy类型表示的图像转换成torch表示的图像。\n",
    "我们用类而不是函数来实现以上这三个功能，主要是考虑到如果用函数的话，每次都需要传入参数，但是用类就可以省掉很多麻烦。我们只需要实现每个类的```__call__```函数和```__init__```函数。\n",
    "\n",
    "下面是对这三个功能的实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rescale(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, landmarks = sample['image'], sample['landmarks']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "\n",
    "        img = transform.resize(image, (new_h, new_w))\n",
    "\n",
    "        # h and w are swapped for landmarks because for images,\n",
    "        # x and y axes are axis 1 and 0 respectively\n",
    "        landmarks = landmarks * [new_w / w, new_h / h]\n",
    "\n",
    "        return {'image': img, 'landmarks': landmarks}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomCrop(object):\n",
    "    \"\"\"Crop randomly the image in a sample.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If int, square crop\n",
    "            is made.\n",
    "    \"\"\"\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, landmarks = sample['image'], sample['landmarks']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        new_h, new_w = self.output_size\n",
    "\n",
    "        top = np.random.randint(0, h - new_h)\n",
    "        left = np.random.randint(0, w - new_w)\n",
    "\n",
    "        image = image[top: top + new_h,\n",
    "                      left: left + new_w]\n",
    "\n",
    "        landmarks = landmarks - [left, top]\n",
    "\n",
    "        return {'image': image, 'landmarks': landmarks}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "    def __call__(self, sample):\n",
    "        image, landmarks = sample['image'], sample['landmarks']\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        return {'image': torch.from_numpy(image),\n",
    "                'landmarks': torch.from_numpy(landmarks)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 组合以上变换功能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设我们现在需要将图像的较短边调整到256，然后从中随机截取224的正方形图像。我们就可以调用```torchvision.transforms.Compose```将以上的```Rescale```和```RandomCrop```两个变换组合起来。\n",
    "\n",
    "以下的代码段展示了分开进行变换以及用```Compose```组合进行变换的结果图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = Rescale(256)\n",
    "crop = RandomCrop(128)\n",
    "composed = transforms.Compose([Rescale(256),\n",
    "                               RandomCrop(224)])\n",
    "\n",
    "# Apply each of the above transforms on sample.\n",
    "fig = plt.figure()\n",
    "sample = face_dataset[2]\n",
    "for i, tsfrm in enumerate([scale, crop, composed]):\n",
    "    transformed_sample = tsfrm(sample)\n",
    "\n",
    "    ax = plt.subplot(1, 3, i + 1)\n",
    "    plt.tight_layout()\n",
    "    ax.set_title(type(tsfrm).__name__)\n",
    "    show_landmarks(**transformed_sample)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 合并dataset与transform、遍历数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简单回顾一下：\n",
    "\n",
    "- 第３小节我们介绍了dataset类;\n",
    "- 第４小节我们我们介绍了怎么样实现各个转换函数，然后将其组合起来。\n",
    "\n",
    "如果你还记得的话，我们在之前定义dataset的时候是有一个transform参数的，但我们在第４节中是先取了样本数据，然后再进行变换操作，并没有将其作为参数传到dataset中。\n",
    "\n",
    "所以我们现在要做的工作就是将所有的内容集成到一起。每次抽取一个样本，都会有以下步骤：\n",
    "\n",
    "- 从文件中读取图片；\n",
    "- 将转换应用于读入的图片；\n",
    "- 由于做了随机选取的操作，所以起到了数据增强的效果。\n",
    "\n",
    "其实我们只要把Transform的部分作为形参传入dataset就可以了，其他的都不变。\n",
    "\n",
    "然后用for循环来依次获得数据集样本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_dataset = FaceLandmarksDataset(csv_file='face_landmarks.csv',\n",
    "                                           root_dir='./faces/',\n",
    "                                           transform=transforms.Compose([\n",
    "                                               Rescale(256),\n",
    "                                               RandomCrop(224),\n",
    "                                               ToTensor()\n",
    "                                           ]))\n",
    "\n",
    "for i in range(len(transformed_dataset)):\n",
    "    sample = transformed_dataset[i]\n",
    "    print(i, sample['image'].size(), sample['landmarks'].size())\n",
    "    if i == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader类介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上我们已经实现了dataset与transform的合并，也实现了用for循环来获取每一个样本数据，好像事情就已经结束了。\n",
    "\n",
    "但等等，真的结束了吗？我们好像还落了什么事情，是的没错：\n",
    "\n",
    "- 按照batch_size获得批量数据；\n",
    "- 打乱数据顺序；\n",
    "- 用多线程multiprocessing来加载数据；\n",
    "\n",
    "torch.utils.data.DataLoader这个类为我们解决了以上所有的问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "只要按照要求设置DataLoader的参数即可:\n",
    "\n",
    "- 第一个参数传入transformed_dataset，即已经用了transform的Dataset实例。\n",
    "- 第二个参数传入batch_size，表示每个batch包含多少个数据。\n",
    "- 第三个参数传入shuffle，布尔型变量，表示是否打乱。\n",
    "- 第四个参数传入num_workers表示使用几个线程来加载数据。\n",
    "\n",
    "如下所示即实现了DataLoader函数的使用，及批样本数据的展示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to show a batch\n",
    "def show_landmarks_batch(sample_batched):\n",
    "    \"\"\"Show image with landmarks for a batch of samples.\"\"\"\n",
    "    images_batch, landmarks_batch = \\\n",
    "            sample_batched['image'], sample_batched['landmarks']\n",
    "    batch_size = len(images_batch)\n",
    "    im_size = images_batch.size(2)\n",
    "\n",
    "    grid = utils.make_grid(images_batch)\n",
    "    plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        plt.scatter(landmarks_batch[i, :, 0].numpy() + i * im_size,\n",
    "                    landmarks_batch[i, :, 1].numpy(),\n",
    "                    s=10, marker='.', c='r')\n",
    "\n",
    "        plt.title('Batch from dataloader')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch在win10中有bug，暂不支持多线程，num_worker只能为0，否则会报：Broken pip的错误\n",
    "dataloader = DataLoader(transformed_dataset, \n",
    "                        batch_size=4,\n",
    "                        shuffle=True, \n",
    "                        num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    print(i_batch, \n",
    "          sample_batched['image'].size(),\n",
    "          sample_batched['landmarks'].size())\n",
    "\n",
    "    # observe 4th batch and stop.\n",
    "    plt.figure()\n",
    "    show_landmarks_batch(sample_batched)\n",
    "    plt.axis('off')\n",
    "    plt.ioff()\n",
    "    plt.show()\n",
    "    if i_batch == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这样呢其实就完成了对数据集完整的处理了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torchvision包提供了一些常用的数据集和转换函数。使用torchvision甚至不需要自己写处理函数。\n",
    "\n",
    "在torchvision中最通用的数据集是ImageFolder，它假设数据结构为如下：\n",
    "\n",
    "```\n",
    "root/ants/xxx.png\n",
    "root/ants/xxy.jpeg\n",
    "root/ants/xxz.png\n",
    ".\n",
    ".\n",
    ".\n",
    "root/bees/123.jpg\n",
    "root/bees/nsdf3.png\n",
    "root/bees/asd932_.png\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里的root指代根目录，ants bees指的是不同的类标签，后面的是具体的图片名称。\n",
    "\n",
    "当然它还提供了对PIL.Image的常用操作，包括RandomHorizontalFlip Scale等等。\n",
    "\n",
    "以下为用torchvision实现的超简化版本的数据处理方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "        transforms.RandomSizedCrop(500),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "root_folder = r'./17flowers/train/'\n",
    "flowers_dataset = datasets.ImageFolder(root=root_folder,\n",
    "                                       transform=data_transform)\n",
    "dataset_loader = torch.utils.data.DataLoader(flowers_dataset,\n",
    "                                             batch_size=4, \n",
    "                                             shuffle=True,\n",
    "                                             num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dl in dataset_loader:\n",
    "    print(dl[0].size(), dl[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to show a batch\n",
    "def show_flowers_batch(sample_batched):\n",
    "    \"\"\"Show image with landmarks for a batch of samples.\"\"\"\n",
    "    images_batch, tags_batch = \\\n",
    "            sample_batched[0], sample_batched[1]\n",
    "    batch_size = len(images_batch)\n",
    "    im_size = images_batch.size(2)\n",
    "    grid = utils.make_grid(images_batch)\n",
    "    plt.imshow(grid.numpy().transpose((1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_batch, sample_batched in enumerate(dataset_loader):\n",
    "    print(i_batch, \n",
    "          sample_batched[0].size(),\n",
    "          sample_batched[1])\n",
    "\n",
    "    # observe 4th batch and stop.\n",
    "    plt.figure()\n",
    "    show_flowers_batch(sample_batched)\n",
    "    plt.axis('off')\n",
    "    plt.ioff()\n",
    "    plt.show()\n",
    "    if i_batch == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
