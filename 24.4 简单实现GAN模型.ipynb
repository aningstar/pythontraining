{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 简单实现GAN模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/gan.jpg' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.models import Model,Sequential\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import Adam\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline\n",
    "# from google.colab import drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，读取Keras自带的mnist数据集。在这里我们给出一个读取数据的函数load_data()。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "def load_data():\n",
    "    (x_train, y_train), (_, _) = mnist.load_data()\n",
    "    x_train = (x_train.astype(np.float32) - 127.5)/127.5\n",
    "    \n",
    "    # Convert shape from (60000, 28, 28) to (60000, 784)\n",
    "    x_train = x_train.reshape(60000, 784)\n",
    "    return (x_train, y_train)\n",
    "\n",
    "X_train, y_train = load_data()\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于本文我们旨在实现最原始的GAN网络，因此用最简单MLP全连接层来构建生成器（用卷积层当然更好，在这里先不考虑）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(units=256, input_dim=100))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    model.add(Dense(units=512))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    model.add(Dense(units=1024))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    model.add(Dense(units=784, activation='tanh'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5))\n",
    "    return model\n",
    "\n",
    "generator = build_generator()\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后建一个判别器，也是一个MLP全连接神经网络："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(units=1024 ,input_dim=784))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.3))\n",
    "       \n",
    "    model.add(Dense(units=512))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.3))\n",
    "       \n",
    "    model.add(Dense(units=256))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.3))\n",
    "      \n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5))\n",
    "    return model\n",
    "  \n",
    "discriminator = build_discriminator()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，我们建立一个GAN网络，由discriminator和generator组成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_GAN(discriminator, generator):\n",
    "    discriminator.trainable=False\n",
    "    GAN_input = Input(shape=(100,))\n",
    "    x = generator(GAN_input)\n",
    "    GAN_output= discriminator(x)\n",
    "    GAN = Model(inputs=GAN_input, outputs=GAN_output)\n",
    "    GAN.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5))\n",
    "    return GAN\n",
    "\n",
    "GAN = build_GAN(discriminator, generator)\n",
    "GAN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后我们给出绘制图像的函数，用于把generator生成的假图片画出来:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_images(generator, epoch, examples=25, dim=(5,5), figsize=(10,10)):\n",
    "    noise= np.random.normal(loc=0, scale=1, size=[examples, 100])\n",
    "    generated_images = generator.predict(noise)\n",
    "    generated_images = generated_images.reshape(25,28,28)\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(generated_images.shape[0]):\n",
    "        plt.subplot(dim[0], dim[1], i+1)\n",
    "        plt.imshow(generated_images[i], interpolation='nearest', cmap='Greys')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    folder = r'./output/mnist_gan/'\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    file_path = os.path.join(folder, 'Generated_images_{0}.png'.format(epoch))\n",
    "    plt.savefig(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后一步，写一个train函数，来训练GAN网络。在这里我们设置最大迭代次数400，每次迭代生成128张假图片。\n",
    "tqdm用来动态显示每次迭代的进度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_GAN(epochs=1, batch_size=128):\n",
    "    #Loading the data\n",
    "    X_train, y_train = load_data()\n",
    "\n",
    "    # Creating GAN\n",
    "    generator= build_generator()\n",
    "    discriminator= build_discriminator()\n",
    "    GAN = build_GAN(discriminator, generator)\n",
    "\n",
    "    for i in range(1, epochs+1):\n",
    "        print(\"Epoch %d\" %i)\n",
    "    \n",
    "        for _ in tqdm(range(batch_size)):\n",
    "            # Generate fake images from random noiset\n",
    "            # 我们生成呈高斯分布的噪声，利用generator，\n",
    "            # 来生成batch_size（128张）图片。每张图片的输入就是一个1*100的噪声矩阵。\n",
    "            noise= np.random.normal(0,1, (batch_size, 100))\n",
    "            fake_images = generator.predict(noise)\n",
    "\n",
    "            # Select a random batch of real images from MNIST\n",
    "            # 同样的，我们从Mnist数据集中随机挑选batch_size张真实图片。\n",
    "            # 我们给真实图片标注1，给假图片标注0，然后将2*batch_size张真假图片混合在一起。\n",
    "            real_images = X_train[np.random.randint(0, X_train.shape[0], batch_size)]\n",
    "\n",
    "            # Labels for fake and real images           \n",
    "            label_fake = np.zeros(batch_size)\n",
    "            label_real = np.ones(batch_size) \n",
    "            # Concatenate fake and real images \n",
    "            X = np.concatenate([fake_images, real_images])\n",
    "            y = np.concatenate([label_fake, label_real])\n",
    "\n",
    "            # Train the discriminator\n",
    "            # 此时，我们利用上文提到的2*batch_size张带标签的真假图片，\n",
    "            # 训练discriminator。训练完毕后，discriminator的weights得到了更新。\n",
    "            discriminator.trainable=True\n",
    "            discriminator.train_on_batch(X, y)\n",
    "\n",
    "            # Train the generator/chained GAN model (with frozen weights in discriminator) \n",
    "            # 然后，我们冻结住discriminator的weights，让discriminator不再变化。\n",
    "            discriminator.trainable=False\n",
    "            # 然后就开始训练generator (chained GAN)。\n",
    "            # 在GAN的训练中，我们输入一堆噪声，期待的输出是将假图片预测为真。\n",
    "            # 在这个过程中，generator继续生成假图片，送到discriminator检验，\n",
    "            # 得到检验结果，如果被鉴定为假，就不断更新自己的权重（假钞贩子不断改良造假技术），\n",
    "            # 直到discriminator将加图片鉴定为真图片（直到当前鉴定假钞的技术无法识别出假钞）。\n",
    "            GAN.train_on_batch(noise, label_real)\n",
    "\n",
    "        # Draw generated images every 10 epoches     \n",
    "        if i == 1 or i % 10 == 0:\n",
    "            draw_images(generator, i)\n",
    "        \n",
    "train_GAN(epochs=400, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，我们总结一下每次迭代发生了什么：\n",
    "\n",
    "- Generator利用自己最新的权重，生成了一堆假图片。\n",
    "- Discrminator根据真假图片的真实label，不断训练更新自己的权重，直到可以顺利鉴别真假图片。\n",
    "- 此时discriminator权重被固定，不再发生变化。generator利用最新的discrimintor，苦苦思索，不断训练自己的权重，最终使discriminator将假图片鉴定为真图片。\n",
    "\n",
    "换成印制假钞的例子，每次迭代发生了如下几件事：\n",
    "\n",
    "- 假钞贩子根据最新造假技术，研发出一代假钞。\n",
    "- 警察反复对比新型假钞和真币的区别，成功改良假钞鉴别方法，从而顺利鉴别出市面流通钞票的真伪。\n",
    "- 假钞贩子生成假钞，马上被警察鉴别出来，痛定思痛，改良技术生成新的假钞。不成想，一上街又被警察识别了出来。日复一日，终于发明了新型假钞，当前的验钞技术已经无法成功检测出这种假钞。\n",
    "\n",
    "然后通过每次迭代，discrimintor (警察的鉴定技术）和generator (假钞制作技术) 都越来越成熟...后来达到了动态平衡。\n",
    "\n",
    "嗯，就这样，是不是挺简单的？\n",
    "\n",
    "今天讲的是最原始的GAN网络，GAN发展到了如今已有许多变种，如将MLP结构换成CNN，Autoencoder，以及loss function的变化等等。我在github上找到一个超级全的用keras编写的各种花式GAN网络集合，有兴趣的小伙伴直接[点击这里](https://link.zhihu.com/?target=https%3A//github.com/eriklindernoren/Keras-GAN)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
